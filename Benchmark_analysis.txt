1. From the results of my Part B driver program, Tree A (ascending order) was built faster at 789 ms and a total processing time of 1ms compared to Tree B (descending order), which was built at 3935 ms and a total processing time of 4ms. Test A's tree is right-heavy because elements are inserted in ascending order, with each greater element placed in the right subtree. This is because the implementation of countGreaterIterative and countGreaterRecursive favors right-tree traversal. Tree B (descending order) is also highly unbalanced, but it forms a left-skewed tree where every node only has a left child. This results in both methods constantly pruning the left subtree, causing errors and inefficient traversal.

2. Tree C (from a shuffled list) was built much faster (14 ms vs. 789 ms for Tree A). Tree A is highly unbalanced with a right height of 4787, whereas Tree C is much more balanced with a left height of 48 and a right height of 156. The shuffled insertion order for Tree C avoids long chains of nodes and creates a structure closer to a balanced tree, drastically reducing the number of traversals through each level.

3. Tree was significantly faster than the list for processing (Tree: 0 ms vs. List: 108 ms). Big-O time complexity for tree processing is O(log n) due to its relatively balanced structure, allowing efficient searching for specific dates. On the other hand, the list has O(n) processing since each query requires a linear traversal of the list.

4. The height of the tree is key to its efficiency. A balanced BST with a height of O(log n) translates to efficient insertions, deletions, and searches, as the number of required traversals will always be a much smaller proportion of a dataset as it grows. An unbalanced tree (e.g., left- or right-skewed) acts like a linked list and thus has a height of O(n), leading to poor performance with large datasets as each node must be traversed from the root to the target.